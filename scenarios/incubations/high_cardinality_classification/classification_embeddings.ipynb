{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate the use of pretrained embedding to classfiy text data with well-described categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from transformers import GPT2TokenizerFast\n",
    "import tiktoken\n",
    "\n",
    "API_KEY = \"\"\n",
    "RESOURCE_ENDPOINT = \"\" \n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\"\n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize text data util function\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_parquet(\"../../data/final_df.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply text normalization\n",
    "df['Consumer complaint narrative']= df[\"Consumer complaint narrative\"].apply(lambda x : normalize_text(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional, use this to filter/cut long text (longer than 8192 tokens)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df[\"Consumer complaint narrative\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df = df[df.n_tokens<8192]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = df[\"Consumer complaint narrative\"].apply(lambda x : get_embedding(x, engine = 'text-embedding-ada-002'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the category description : embedding map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the category descriptions (unlike normal classification, the more detail, more clear, more distinctive description the better)\n",
    "# produce the embedding for each category description \n",
    "import numpy as np\n",
    "issues = np.unique(df.Issue)\n",
    "issue_emb = {issue:get_embedding(issue, engine = 'text-embedding-ada-002')for issue in issues}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_emb['APR or interest rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "  \n",
    "import numpy as np  \n",
    "  \n",
    "def categorize(input_vector):  \n",
    "    \"\"\"  \n",
    "    Given an input vector and a dictionary of label vectors,  \n",
    "    returns the label with the highest cosine similarity to the input vector.  \n",
    "    \"\"\"  \n",
    "    max_similarity = float('-inf')  \n",
    "    max_label = None  \n",
    "      \n",
    "    # Compute cosine similarity between input vector and each label vector  \n",
    "    for label, vector in issue_emb.items():  \n",
    "        cosine_similarity = np.dot(input_vector, vector) / (np.linalg.norm(input_vector) * np.linalg.norm(vector))  \n",
    "          \n",
    "        # Update max_similarity and max_label if necessary  \n",
    "        if cosine_similarity > max_similarity:  \n",
    "            max_similarity = cosine_similarity  \n",
    "            max_label = label  \n",
    "      \n",
    "    return max_label  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction or matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction\"] = df[\"embedding\"].apply(categorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count accuracy. \n",
    "df[df[\"prediction\"] ==df[\"Issue\"]].count()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Consumer complaint narrative','Issue','prediction']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach using ChatGPT and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "user_message = \"\"\n",
    "def classify(text):\n",
    "    user_message =f\"\"\" \n",
    " classify the following input into one of the following category {issues}\n",
    " <<input>>\n",
    " {text}\n",
    " <<input>>\n",
    " The category of the input is:\n",
    "\"\"\"\n",
    "    i=0\n",
    "    while i<10:\n",
    "\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                engine=\"gpt-35-turbo\", # engine = \"deployment_name\".\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\":user_message },\n",
    "                ]\n",
    "            )\n",
    "            return response['choices'][0]['message']['content']\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            i+=1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = df['Consumer complaint narrative'].values\n",
    "chatgpt_predictions =[]\n",
    "for complaint in complaints:\n",
    "    result = classify(complaint)\n",
    "    chatgpt_predictions.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chatgpt_predictions'] =chatgpt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"chatgpt_predictions\"] ==df[\"Issue\"]].count()/df.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
